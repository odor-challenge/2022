<!DOCTYPE html>
<html lang="en">

<head>
    <title>FVC</title>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">


    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link href="fonts/icomoon/style.css" rel="stylesheet">
    <link crossorigin="anonymous" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" rel="stylesheet">

    <link href="css/jquery-ui.css" rel="stylesheet">
    <link href="css/owl.carousel.min.css" rel="stylesheet">
    <link href="css/owl.theme.default.min.css" rel="stylesheet">
    <link href="css/owl.theme.default.min.css" rel="stylesheet">

    <link href="css/jquery.fancybox.min.css" rel="stylesheet">

    <link href="fonts/flaticon/font/flaticon.css" rel="stylesheet">

    <link href="css/aos.css" rel="stylesheet">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link href="css/style.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-88572407-1', 'auto');
        ga('send', 'pageview');
    </script>
</head>

<body data-offset="300" data-spy="scroll" data-target=".site-navbar-target">

<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">
            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

    <div class="header-top">
        <div class="container">
            <div class="row align-items-center">
                <div class="col-12 col-lg-6 d-flex">
                    <a class="site-logo" href="index.html">
                        Future Video Conferencing (FVC)
                    </a>
                    <a class="ml-auto d-inline-block d-lg-none site-menu-toggle js-menu-toggle text-black"
                       href="#"><span
                            class="icon-menu h3"></span></a>

                </div>
                <div class="col-12 col-lg-6 ml-auto d-flex">
                    <div class="ml-md-auto top-social d-none d-lg-inline-block">
                        <a class="d-inline-block p-3" href="#"> </a>
                        <a class="d-inline-block p-3" href="#"> </a>
                        <a class="d-inline-block p-3" href="#"> </a>
                    </div>

                </div>
                <!--          <div class="col-6 d-block d-lg-none text-right">-->

            </div>
        </div>
    </div>
    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner">

        <div class="container">

            <div class="d-flex align-items-center">

                <div class="mr-auto">
                    <nav class="site-navigation position-relative text-right" role="navigation">
                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li class="active">
                                <a class="nav-link text-left" href="index.html">Home</a>
                            </li>
                            <li>
                                <a class="nav-link text-left" href="index.html#dates">Important dates</a>
                            </li>
                            <li>
                                <a href="index.html#schedule" class="nav-link text-left">Schedule</a>
                            </li>
                            <li>
                                <a href="index.html#speakers" class="nav-link text-left">Speakers</a>
                            </li>
                            <li>
                                <a href="index.html#organizers" class="nav-link text-left">Organizers</a>
                            </li>
                            <!--                  <li class="nav-item dropdown">
                                                 <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                      Challenge
                                    </a>
                                             <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                              <a class="dropdown-item" href="challenge.html#challenge1">Object semantic segmentation with image-level supervision</a>
                                              <a class="dropdown-item" href="challenge.html#challenge2">Scene parsing with point-based supervision</a>
                                            </div>
                                            </li> -->
                            <li>
                                <a class="nav-link text-left" href="challenge.html">Challenge</a>
                            </li>

                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>


<div class="site-section">
    <div class="container">
        <div class="row">
            <!-- Challenge 1-->
            <div class="col-lg-12" id="challenge1">

                <!-- <p style="text-align: justify">We will organize the second Learning from Imperfect Data (LID) challenge on object semantic segmentation and scene parsing, which includes two competition tracks.  </p>  （<strong>challenge deadline: June 8, 2019</strong>） -->
                <p>All datasets are well prepared. We will employ CodaLab to host these two tracks.</p>  
                <!--（<strong>challenge deadline: June 8, 2019</strong>）-->

                <div class="section-title">
                    <h1>Track1</h1>
                    <h4>Human-centric video matting</h4>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">
                        <p>
                            This challenge aims to perform efficient and accurate portrait matting in videos, which can be
                            applied to real video conferencing scenarios such as setting virtual background. To this end, we
                            collect the data from a group of volunteers using green background. We ask each volunteer to conduct
                            one freestyle action and several standard actions, including left/right moving, back/forth walking,
                            left/right twisting, flicking hair, waving hand before the face, before the camera. We finally
                            acquire videos with a total length over half an hour, 25 fps, a scale of 1080P. Each record video
                            is well trimmed and Adobe After Effect is employed to extract ground-truth foreground portrait
                            and alpha matte for each frame. Competitors are welcome to utilize the provided data to
                            perform data augmentation and build their own training data. Similar to image matting, several popular metrics such
                            as MSE, SAD, are used to evaluate the performance.
                        </p>
                        <!-- </br> -->
                    </div>
                </div>
            </div>

            <!-- Challenge 2-->

            <div class="col-lg-12" id="challenge2">
                <div class="section-title">
                    <h1>Track2</h1>
                    <h4>Human-centric video coding for action analysis</h4>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">
                        <!-- <p> Beyond object segmentation, background categories such as wall, road, sky need to be further specified for the scene parsing, which is a challenging task compared with object semantic segmentation. Thus, it will be more difficult and expensive to manually annotate pixel-level mask for this task. In this track, we propose to leverage several labeled points that are much easier to obtain to guide the training process.
      The dataset is built upon the well-known ADE20K, which includes 20,210 training images from 150 categories. We provide the point-based annotations on the training set. Please download the data from <a href="http://sceneparsing.csail.mit.edu/data/LID2019"> LID Challenge Track2 data </a>. <br/> -->
                        <p> 
                            This challenge aims to develop new image/video pre-editing methods for human-centric frame
                            reconstruction jointly with the related analysis, i.e. action recognition, which provides the
                            technical basis for highly efficient video compression and transmission for conferencing
                            scenarios. The competitors are allowed to pre-edit video frames. Then, we will compress these
                            frames with the same bit-rate constraint with existing codecs, e.g. HEVC, and calculate the
                            evaluation metrics on the decoded frames. To this end, PKU-MMD is adopted as an evaluation
                            dataset. PKU-MMD phase 1 contains 1076 long video sequences in 51 action categories,
                            performed by 66 subjects in three camera views. It contains almost 20,000 action instances and
                            5.4 million frames in total. Each video lasts about 3-4 minutes (recording ratio set to 30 FPS)
                            and contains approximately 20 action instances. The total scale of our dataset is 5,312,580
                            frames of 3,000 minutes with 21,545 temporally localized actions. In this challenge, we will
                            select the video sequences of 10 action categories for training and testing. In the evaluation, we
                            will calculate two kinds of metrics on the decoded results of the pre-editing videos: human
                            region frame reconstruction error and action recognition accuracy. For the former, for a frame,
                            we will calculate PSNR and SSIM results of the regions in the bounding boxes that tightly
                            enclose persons. For the latter, common metrics such as F1-Score, Interpolated Average
                            Precision, Mean Average Precision of Actions, Mean Average Precision of Videos are used to
                            evaluate the performance.
                        </p>
                    </div>
                </div>
            </div>




    </div>

    <div class="col-lg-12" id="challenge2">
        <div style="display:inline-block;width:500px;">
            <script async="async" src="//rc.rev
            olvermaps.com/0/0/7.js?i=2hlmeh3dic1&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;br=19&amp;sx=0"
                    type="text/javascript"></script>
        </div>
    </div>
</div>
</div>
<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | This template is made with <i aria-hidden="true"
                                                                            class="icon-heart text-danger"></i> by
                        <a href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                    </p>
                </div>
            </div>
        </div>
    </div>
</div>


</div>
<!-- .site-wrap -->


<!-- loader -->
<div class="show fullscreen" id="loader">
    <svg class="circular" height="48px" width="48px">
        <circle class="path-bg" cx="24" cy="24" fill="none" r="22" stroke="#eeeeee" stroke-width="4"/>
        <circle class="path" cx="24" cy="24" fill="none" r="22" stroke="#ff5e15" stroke-miterlimit="10"
                stroke-width="4"/>
    </svg>
</div>

<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>


<script src="js/main.js"></script>

</body>

</html>